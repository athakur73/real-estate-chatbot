ğŸ¡ Agent Mira â€“ Backend Service

AI-Powered Real Estate Chatbot (FastAPI + LangGraph + Gemini)

ğŸ“Œ Overview

This backend powers Agent Mira, an AI-driven real estate assistant that enables users to search for properties using natural language queries.

The backend is designed with production principles:

* Deterministic data handling
* Responsible LLM usage
* Explicit agent orchestration
* Clean separation of concerns

The system converts conversational input into structured filters, applies them deterministically to property data, and returns accurate results.

ğŸ¯ Core Capabilities

* Natural language property search
* Multi-constraint filtering (location, budget, bedrooms, amenities)
* Session-based conversation handling
* Saved properties persistence (MongoDB)
* LLM-powered intent extraction (Gemini)
* Deterministic property filtering (Python)

)

ğŸ§  Key Design Principle

LLMs interpret intent â€” application code enforces truth.

The LLM is never used for:

* Filtering logic
* Data mutation
* Business decisions

All critical operations remain deterministic.

ğŸ—ï¸ High-Level Architecture
        Client (React)
        â†“
        FastAPI (/chat, /save)
        â†“
        LangGraph Agent
        â”œâ”€â”€ Intent Extraction (Gemini)
        â”œâ”€â”€ Property Filtering (Python)
        â””â”€â”€ Response Builder
        â†“
        JSON Response
Saved properties are persisted independently in MongoDB.

ğŸ§© Tech Stack
Backend Framework
    * Python 3.11+
    * FastAPI
    * Uvicorn

AI / Agent Layer

    * LangChain
    * LangGraph
    * Google Gemini API

Data & Storage

    * JSON property datasets
    * MongoDB (saved properties)

ğŸ“‚ Project Structure
    app/
    â”œâ”€â”€ main.py                  # FastAPI entry point
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ chat.py              # /chat endpoint
    â”‚   â”œâ”€â”€ save.py              # /save endpoint
    â”‚   â””â”€â”€ schemas.py           # Request/response models
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ real_estate_agent.py # LangGraph agent
    â”‚   â””â”€â”€ nodes.py             # Agent nodes
    â”œâ”€â”€ services/
    â”‚   â”œâ”€â”€ query_extractor.py   # LLM intent extraction
    â”‚   â”œâ”€â”€ property_filter.py   # Deterministic filtering
    â”‚   â”œâ”€â”€ property_loader.py   # JSON merge logic
    â”‚   â””â”€â”€ gemini_llm.py        # Gemini client
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ properties_basic.json
    â”‚   â”œâ”€â”€ property_images.json
    â”‚   â””â”€â”€ property_characteristics.json
    â””â”€â”€ db/
        â””â”€â”€ mongodb.py           # MongoDB integration

ğŸ”„ Agent Flow (LangGraph)

Each user query passes through explicit agent states:

1. User Input
    * Receives raw user message

2. Intent Extraction
    * Gemini converts text â†’ structured filters
    * Output validated against schema

3. Filter Execution
    * Python applies filters on merged dataset
    * No AI involvement

4. Response Generation
    * Final reply + matching properties returned

LangGraph ensures:
    * Clear execution order
    * Debuggable state transitions
    * Easy extensibility

ğŸ“Š Property Data Handling
Property data is distributed across multiple JSON files:

    * Basic details
    * Location & pricing
    * Amenities & metadata

These files are merged at application startup into a single in-memory dataset.
    âœ” Deterministic
    âœ” Fast
    âœ” No runtime LLM dependency

ğŸ’¾ Saved Properties (MongoDB)
Users can save properties via the /save endpoint.

Design Highlights
    * Stateless search
    * Persistent user actions
    * Session-based identification
    * Idempotent saves

This allows future extension to:

    * User accounts
    * Saved searches
    * Recommendations

ğŸš€ Running the Backend Locally
1ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Set Environment Variables
export GOOGLE_API_KEY=your_api_key
export MONGO_URI=mongodb://localhost:27017

4ï¸âƒ£ Start Server
uvicorn app.main:app --reload

API will be available at:
http://localhost:8000

ğŸ”Œ API Endpoints
POST /chat
Processes user queries and returns matching properties.

Request
    {
    "message": "Show me 3-bedroom homes in Dallas under 600K",
    "session_id": "uuid"
    }

Response
    {
    "reply": "Here are some matching properties.",
    "count": 2,
    "properties": [...]
    }

POST /save

Saves a property for the current session.
Request:
{
  "property_id": "prop_123",
  "session_id": "uuid"
}

ğŸ“ˆ Scalability & Future Enhancements

    * Redis for session memory
    * Authentication & user profiles
    * RAG for schools & neighborhood data
    * Streaming responses
    * Analytics & personalization
    * Caching for LLM responses

ğŸ§  Key Engineering Takeaways

    * Explicit agent orchestration
    * Responsible LLM usage
    * Deterministic business logic
    * Production-aware error handling
    * Clean separation of AI vs system logic
